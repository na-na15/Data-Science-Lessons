{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNettiBdQYSvwtpz9EBr4o8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/na-na15/Data-Science-Lessons/blob/master/DataCollection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ4OFZ8Fbmtg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This file is about collecting data\n",
        "\n"
      ],
      "metadata": {
        "id": "qiMs2vJ7dptN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "#For calling API and creating file.\n",
        "import requests\n",
        "import json\n",
        "import time"
      ],
      "metadata": {
        "id": "qCOmOhsTcDYZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First way: using URL"
      ],
      "metadata": {
        "id": "i43b3Z__GSfV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b5215ab-58d3-492c-d802-826396b98060",
        "id": "fZufLoXNcI8P"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status code: 403\n",
            "Failed to retrieve the page\n"
          ]
        }
      ],
      "source": [
        "#import requests\n",
        "#import time\n",
        "url = \"https://weworkremotely.com/categories/remote-programming-jobs\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0\",\n",
        "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
        "    \"Connection\": \"keep-alive\",\n",
        "    \"Referer\": \"https://weworkremotely.com\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "time.sleep(2)\n",
        "print(\"Status Code:\", response.status_code)\n",
        "print(response.text[:1000])  # show first 1000 characters of the HTML page\n",
        "\n",
        "\n",
        "url = \"https://remoteok.com/remote-data-jobs\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "#Second way to understand the errors\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "print(\"Status code:\", response.status_code)\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    jobs = soup.find_all(\"tr\", class_=\"job\")\n",
        "\n",
        "    print(f\"Found {len(jobs)} jobs\")\n",
        "\n",
        "    for job in jobs[:5]:  # Show only first 5 for now\n",
        "        title = job.find(\"h2\")\n",
        "        company = job.find(\"h3\")\n",
        "        if title and company:\n",
        "            print(\"Job Title:\", title.text.strip())\n",
        "            print(\"Company:\", company.text.strip())\n",
        "            print(\"---\")\n",
        "else:\n",
        "    print(\"Failed to retrieve the page\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)API"
      ],
      "metadata": {
        "id": "R28HEmX9f0l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import requests\n",
        "#import json\n",
        "\n",
        "#API Credentials:\n",
        "APP_ID = \"292541ce\"\n",
        "APP_KEY = \"314d9a8495ed19f7b0d89c0ac5e824ed\"\n",
        "\n",
        "#API Endpoint and Parameters:\n",
        "# Define the API endpoint and parameters\n",
        "endpoint = \"https://api.adzuna.com/v1/api/jobs/us/search/1\"\n",
        "params = {\n",
        "    \"app_id\": APP_ID,\n",
        "    \"app_key\": APP_KEY,\n",
        "    \"results_per_page\": 500,  # Adjust as needed\n",
        "    \"what\": \"data analyst\",   # you can change this job title\n",
        "    \"content-type\": \"application/json\"\n",
        "}\n",
        "\n",
        "#Send request\n",
        "response = requests.get(endpoint, params=params)\n",
        "# Check response\n",
        "print(\"Status Code:\", response.status_code)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    print(\"Success! Found\", len(data[\"results\"]), \"jobs.\")\n",
        "else:\n",
        "    print(\"Failed to retrieve data:\", response.text[:300])"
      ],
      "metadata": {
        "id": "bj1J4R05gBFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ee330f-f253-455d-aeeb-9fb07cf595f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Success! Found 50 jobs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_job = data[\"results\"][0]\n",
        "print(type(first_job),\"PP\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt27WZyF1yjR",
        "outputId": "45b14b61-f2b3-4d0b-d745-13931bcba18d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'> PP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_job = data[\"results\"][0]\n",
        "for key, value in first_job.items():\n",
        "    print(f\"{key}: {value}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sl2SRKx6os-",
        "outputId": "500ac35f-189c-4f6e-fda5-01fd8d8d3eb0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "latitude: 35.154363\n",
            "\n",
            "longitude: -90.060664\n",
            "\n",
            "redirect_url: https://www.adzuna.com/land/ad/5127897416?se=dq52NCYi8BGkiSfR3LWCew&utm_medium=api&utm_source=292541ce&v=A0EC529A5AD068F14221DC9B9F4FE2A69F88B54B\n",
            "\n",
            "salary_is_predicted: 1\n",
            "\n",
            "description: Job Title: Data Analyst Location: REMOTE About Us : At Girls Scouts, we’re on a mission to turn data into actionable insights that drive decision-making and innovation. As a fast-growing company, we understand that data is at the heart of everything we do. We are looking for a talented and driven Data Analyst to join our team and help us unlock the power of data to optimize processes, improve customer experiences, and achieve business success. Why You’ll Love Working With Us: Impactful Work: Yo…\n",
            "\n",
            "__CLASS__: Adzuna::API::Response::Job\n",
            "\n",
            "salary_max: 79069.45\n",
            "\n",
            "adref: eyJhbGciOiJIUzI1NiJ9.eyJzIjoiZHE1Mk5DWWk4QkdraVNmUjNMV0NldyIsImkiOiI1MTI3ODk3NDE2In0.cD4ZE9c4Y8CDGy3X9QIgIV2wpzH88p2lSMBBchxx-m0\n",
            "\n",
            "title: DATA ANALYST\n",
            "\n",
            "id: 5127897416\n",
            "\n",
            "category: {'label': 'IT Jobs', '__CLASS__': 'Adzuna::API::Response::Category', 'tag': 'it-jobs'}\n",
            "\n",
            "created: 2025-04-03T16:49:41Z\n",
            "\n",
            "company: {'__CLASS__': 'Adzuna::API::Response::Company', 'display_name': 'Girl Scouts'}\n",
            "\n",
            "location: {'__CLASS__': 'Adzuna::API::Response::Location', 'area': ['US', 'Tennessee', 'Shelby County', 'Memphis'], 'display_name': 'Memphis, Shelby County'}\n",
            "\n",
            "salary_min: 79069.45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#import json\n",
        "#Understand the structure of one job posting\n",
        "#Let’s print one of the job postings with json.dumps() to make it easier to read:\n",
        "first_job = data[\"results\"][0]\n",
        "print(json.dumps(first_job, indent=2),\":)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJDbE6Tw9mSo",
        "outputId": "3541deb6-e113-4d69-e976-6f5a930c2f28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"latitude\": 35.154363,\n",
            "  \"longitude\": -90.060664,\n",
            "  \"redirect_url\": \"https://www.adzuna.com/land/ad/5127897416?se=dq52NCYi8BGkiSfR3LWCew&utm_medium=api&utm_source=292541ce&v=A0EC529A5AD068F14221DC9B9F4FE2A69F88B54B\",\n",
            "  \"salary_is_predicted\": \"1\",\n",
            "  \"description\": \"Job Title: Data Analyst Location: REMOTE About Us : At Girls Scouts, we\\u2019re on a mission to turn data into actionable insights that drive decision-making and innovation. As a fast-growing company, we understand that data is at the heart of everything we do. We are looking for a talented and driven Data Analyst to join our team and help us unlock the power of data to optimize processes, improve customer experiences, and achieve business success. Why You\\u2019ll Love Working With Us: Impactful Work: Yo\\u2026\",\n",
            "  \"__CLASS__\": \"Adzuna::API::Response::Job\",\n",
            "  \"salary_max\": 79069.45,\n",
            "  \"adref\": \"eyJhbGciOiJIUzI1NiJ9.eyJzIjoiZHE1Mk5DWWk4QkdraVNmUjNMV0NldyIsImkiOiI1MTI3ODk3NDE2In0.cD4ZE9c4Y8CDGy3X9QIgIV2wpzH88p2lSMBBchxx-m0\",\n",
            "  \"title\": \"DATA ANALYST\",\n",
            "  \"id\": \"5127897416\",\n",
            "  \"category\": {\n",
            "    \"label\": \"IT Jobs\",\n",
            "    \"__CLASS__\": \"Adzuna::API::Response::Category\",\n",
            "    \"tag\": \"it-jobs\"\n",
            "  },\n",
            "  \"created\": \"2025-04-03T16:49:41Z\",\n",
            "  \"company\": {\n",
            "    \"__CLASS__\": \"Adzuna::API::Response::Company\",\n",
            "    \"display_name\": \"Girl Scouts\"\n",
            "  },\n",
            "  \"location\": {\n",
            "    \"__CLASS__\": \"Adzuna::API::Response::Location\",\n",
            "    \"area\": [\n",
            "      \"US\",\n",
            "      \"Tennessee\",\n",
            "      \"Shelby County\",\n",
            "      \"Memphis\"\n",
            "    ],\n",
            "    \"display_name\": \"Memphis, Shelby County\"\n",
            "  },\n",
            "  \"salary_min\": 79069.45\n",
            "} :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all jobs to a file\n",
        "with open(r\"C:\\Users\\nazem\\Desktop\\MyProject\\career_switch_app\\jobs_data.json\", \"w\") as f:\n",
        "    json.dump(data[\"results\"], f, indent=2)\n",
        "\n",
        "print(\"Data saved successfully!!!!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9LPcopl9ofr",
        "outputId": "c576108d-ae84-4cb9-b273-154141ec5964"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved successfully!!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary:\n",
        "Initially, the code was correctly saving a JSON file with job listings using the open() function.\n",
        "However, I was running the code in Google Colab, which saves files inside a virtual environment (not my actual desktop).\n",
        "That’s why I couldn’t see the saved file in the path I expected on my computer.\n",
        "To fix this, I used Google Colab’s built-in 'files.download()' method to download the saved file from the Colab environment to my local machine.\n",
        "This approach works well without needing to mount Google Drive.\n"
      ],
      "metadata": {
        "id": "bddDIHgDHVWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "# Save the JSON file\n",
        "with open(\"jobs_data.json\", \"w\") as f:\n",
        "    json.dump(data[\"results\"], f, indent=2)\n",
        "\n",
        "print(\"✅ File saved successfully!\")\n",
        "\n",
        "# Download the file to your computer\n",
        "files.download(\"jobs_data.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "DOUrNAZXGyAh",
        "outputId": "809874c1-463e-4d61-b1a1-853dad4c12df"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ File saved successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_86bdfbd6-2133-4464-91b1-653f2e21c7d3\", \"jobs_data.json\", 81753)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XiPz5MBJG5vg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}